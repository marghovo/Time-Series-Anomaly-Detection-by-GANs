{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from torch import nn, optim\n",
    "from networks import DNet, GNet\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import OneClassSVM\n",
    "from matplotlib import pyplot as plot\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary\n",
    "# seasonal\n",
    "# trendy\n",
    "\n",
    "df = pd.read_csv(\"data/stationary-arma-ts.csv\")\n",
    "ts = df[\"# Data\"]\n",
    "print(df['# Data'].describe())\n",
    "print(\"\\n\")\n",
    "print(\"Shape of TS: \" + str(ts.shape))\n",
    "print(\"Type of TS: \" + str(type(ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_scaler = scale(ts)\n",
    "ts_scaled = ts_scaler[\"scaled\"].values\n",
    "ts_scaled = ts_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_trd_train = strongest_trend_period(ts_scaled.reshape(ts_scaled.shape[0], ), 1, 25)\n",
    "str_trd_train[\"period\"]\n",
    "\n",
    "detrended_train = remove_trend(ts_scaled.reshape(ts_scaled.shape[0], ), str_trd_train[\"period\"])\n",
    "if(linearity_score(detrended_train[\"trend\"].reshape(detrended_train[\"trend\"].shape[0], )) >= 0.8):\n",
    "    ts_scaled = detrended_train[\"detrended\"]\n",
    "    ts_detrended_train_scaler = scale(pd.Series(ts_scaled.reshape(ts_scaled.shape[0], )))\n",
    "    ts_scaled = ts_detrended_train_scaler[\"scaled\"].values\n",
    "\n",
    "str_period_train = strongest_seasonal_period(ts_scaled.reshape(ts_scaled.shape[0], ), 1, 25)\n",
    "if(str_period_train[\"seasonality_strength\"] >= 0.8):\n",
    "    batch_size = str_period_train[\"period\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ts_scaled[:12012]\n",
    "train = torch.Tensor(train)\n",
    "x_train = train[:12000]\n",
    "y_train = train[12:12012]\n",
    "x_train = x_train.reshape(1000, 12)\n",
    "y_train = y_train.reshape(1000, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ts_scaled[12012:12144]\n",
    "test = torch.Tensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test[:120]\n",
    "y_test = test[12:]\n",
    "x_test = x_test.reshape(10, 12)\n",
    "y_test = y_test.reshape(10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dNet = DNet()\n",
    "gNet = GNet()\n",
    "dNet.to(device)\n",
    "gNet.to(device)\n",
    "d_optimizer = optim.Adam(dNet.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(gNet.parameters(), lr=0.0002)\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_d(optimizer, real_data, fake_data, device):\n",
    "    N = real_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred_real = dNet(real_data)\n",
    "    error_real = loss(pred_real, ones_target(N, device))\n",
    "    error_real.backward()\n",
    "\n",
    "    pred_fake = dNet(fake_data)\n",
    "    error_fake = loss(pred_fake, zeros_target(N, device))\n",
    "    error_fake.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    error_total = error_real + error_fake\n",
    "    return error_total, pred_real, pred_fake\n",
    "\n",
    "\n",
    "def train_g(optimizer, real_data, fake_data, device):\n",
    "    N = fake_data.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = dNet(fake_data)\n",
    "\n",
    "    error = loss(pred, ones_target(N, device))\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "d_loss_array = []\n",
    "g_loss_array = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    gNet.train()\n",
    "    dNet.train()\n",
    "    for n_batch, (inputs, targets) in enumerate(train_dataloader):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        real_data = targets\n",
    "        \n",
    "        fake_data = gNet(inputs).detach()\n",
    "\n",
    "        \n",
    "        d_error, d_pred_real, d_pred_fake = train_d(d_optimizer, real_data, fake_data, device)\n",
    "        \n",
    "        fake_data = gNet(inputs)\n",
    "        \n",
    "        g_error = train_g(g_optimizer, real_data, fake_data, device)\n",
    "        \n",
    "        r = targets[0, :].reshape(12, )\n",
    "        f = fake_data[0, :].reshape(12, )\n",
    "        \n",
    "        d_loss_array.append(d_error.item())\n",
    "        g_loss_array.append(g_error.item())\n",
    "        \n",
    "    plot.plot(np.array(r.cpu()), label=\"real\")\n",
    "    plot.plot(np.array(f.cpu().detach()), label=\"generated\")\n",
    "    plot.legend(loc = \"upper right\")\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gNet.state_dict(), \"gNet_good.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dNet.state_dict(), \"dNet_good.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gNet = GNet()\n",
    "gNet.to(device)\n",
    "gNet.load_state_dict(torch.load(\"models/gNet_good.pth\", map_location=torch.device('cpu')))\n",
    "gNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_all = []\n",
    "generated_all = []\n",
    "y_dim_0 = y_test.shape[0]\n",
    "y_dim_1 = y_test.shape[1]\n",
    "\n",
    "# modified x_test\n",
    "\n",
    "# Point \n",
    "# 6\n",
    "\n",
    "# y_test[0, 7] = 1.5\n",
    "# y_test[1, 4] = 4\n",
    "# y_test[1, 11] = -2\n",
    "# y_test[2, 9] = 7\n",
    "# y_test[5, 2] = 10\n",
    "# y_test[8, 5] = 3\n",
    "\n",
    "# Sequantial Anomalies\n",
    "# 8\n",
    "\n",
    "# y_test[0, 7] = 10\n",
    "\n",
    "# y_test[4, 1] = 5\n",
    "# y_test[4, 2] = 5\n",
    "# y_test[4, 3] = 5\n",
    "# y_test[4, 4] = 5\n",
    "# y_test[4, 5] = 5\n",
    "# y_test[4, 6] = 5\n",
    "# y_test[4, 7] = 5\n",
    "\n",
    "\n",
    "#Sequential and sequential\n",
    "# 13\n",
    "\n",
    "# y_test[0, 7] = 25\n",
    "\n",
    "# y_test[5, 1] = 15\n",
    "# y_test[5, 2] = 15\n",
    "# y_test[5, 3] = 15\n",
    "# y_test[5, 4] = 15\n",
    "# y_test[5, 5] = 15\n",
    "# y_test[5, 6] = 15\n",
    "# y_test[5, 7] = 15\n",
    "\n",
    "# y_test[7, 4] = 10\n",
    "# y_test[7, 5] = 10\n",
    "# y_test[7, 6] = 10\n",
    "# y_test[7, 7] = 10\n",
    "# y_test[7, 8] = 10\n",
    "\n",
    "\n",
    "# Seq and Point\n",
    "# 11\n",
    "\n",
    "y_test[0, 7] = 25\n",
    "y_test[3, 5] = 30\n",
    "\n",
    "y_test[5, 1] = 12\n",
    "y_test[5, 2] = 12\n",
    "y_test[5, 3] = 12\n",
    "y_test[5, 4] = 12\n",
    "y_test[5, 5] = 12\n",
    "y_test[5, 6] = 12\n",
    "y_test[5, 7] = 12\n",
    "\n",
    "y_test[7, 4] = 20\n",
    "y_test[9, 6] = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(y_dim_0-1):\n",
    "    a = x_test[i, :]\n",
    "    real = y_test[i, :]\n",
    "    a = a.to(device)\n",
    "    real = real.to(device)\n",
    "    generated = gNet(a)\n",
    "    \n",
    "    real_all.append(np.array(real.cpu()))\n",
    "    generated_all.append(np.array(generated.cpu().detach()))\n",
    "\n",
    "real_all = np.asarray(real_all)\n",
    "generated_all = np.asarray(generated_all)\n",
    "\n",
    "real_all = real_all.reshape(y_dim_0*y_dim_1-12, )\n",
    "generated_all = generated_all.reshape(y_dim_0*y_dim_1-12, )\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(real_all, label=\"Real Data\")\n",
    "ax.plot(generated_all, label=\"Generated\")\n",
    "plot.legend(loc = \"upper right\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AD by GAN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = real_all - generated_all\n",
    "\n",
    "residual_mean = np.mean(residual)\n",
    "residual_stdev = np.std(residual)\n",
    "upper_bound = residual_mean + (2*residual_stdev)\n",
    "lower_bound = residual_mean - (2*residual_stdev)\n",
    "\n",
    "upper_ci = generated_all + 1.96 * residual_stdev\n",
    "lower_ci = generated_all - 1.96 * residual_stdev\n",
    "\n",
    "anomaly_indices = []\n",
    "anomaly_values = []\n",
    "for i in range(real_all.shape[0]):\n",
    "    if real_all[i] >= upper_ci[i] or real_all[i] <= lower_ci[i]:\n",
    "        anomaly_indices.append(i)\n",
    "        anomaly_values.append(real_all[i])\n",
    "        \n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(real_all, label=\"Real Data\")\n",
    "ax.plot(generated_all, label=\"Generated\")\n",
    "ax.plot(upper_ci, color=\"#000000\")\n",
    "ax.plot(lower_ci, color=\"#000000\")\n",
    "plot.scatter(x=anomaly_indices, y=anomaly_values, color=\"#cd8fa3\", label=\"Anomaly\")\n",
    "plot.legend(loc = \"upper right\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (- hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = real_all.reshape(-1, 1)\n",
    "n_cluster = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(n_cluster, scores)\n",
    "plot.xlabel('Number of Clusters')\n",
    "plot.ylabel('Score')\n",
    "plot.title('Elbow Curve')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = real_all.reshape(-1, 1)\n",
    "km = KMeans(n_clusters=5)\n",
    "km.fit(X)\n",
    "km.predict(X)\n",
    "labels = km.labels_\n",
    "\n",
    "outliers_fraction = 0.01\n",
    "\n",
    "distance = getDistanceByPoint(data, kmeans[9])\n",
    "number_of_outliers = int(outliers_fraction*len(distance))\n",
    "threshold = distance.nlargest(number_of_outliers).min()\n",
    "real_data_pd = pd.DataFrame(real_all)\n",
    "real_data_pd['anomaly'] = (distance >= threshold).astype(int)\n",
    "\n",
    "anomaly_k_means = real_data_pd.loc[real_data_pd['anomaly'] == 1, [0]]\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(real_data_pd[0], color='blue', label='Real Data')\n",
    "ax.scatter(anomaly_k_means[0].index, anomaly_k_means[0], color='red', label='Anomaly')\n",
    "plot.xlabel('Time')\n",
    "plot.legend()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = real_all.reshape(-1, 1)\n",
    "real_data_pd = pd.DataFrame(real_all)\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "\n",
    "outliers_fraction = 0.03\n",
    "model =  IsolationForest(contamination=outliers_fraction)\n",
    "model.fit(data) \n",
    "real_data_pd['anomaly'] = pd.Series(model.predict(data))\n",
    "\n",
    "anomaly_isolation_forest = real_data_pd.loc[real_data_pd['anomaly'] == -1, [0]]\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(real_data_pd[0], color='blue', label='Real Data')\n",
    "ax.scatter(anomaly_k_means_isolation_forest[0].index, anomaly_k_means_isolation_forest[0], color='red', label='Anomaly')\n",
    "plot.xlabel('Time')\n",
    "plot.legend()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = real_all.reshape(-1, 1)\n",
    "real_data_pd = pd.DataFrame(real_all)\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "\n",
    "\n",
    "outliers_fraction = 0.03\n",
    "model = OneClassSVM(nu=outliers_fraction, kernel=\"rbf\", gamma=0.01)\n",
    "model.fit(data)\n",
    "real_data_pd['anomaly'] = pd.Series(model.predict(data))\n",
    "\n",
    "\n",
    "anomaly_svm = real_data_pd.loc[real_data_pd['anomaly'] == -1, [0]]\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(10,6))\n",
    "ax.plot(real_data_pd[0], color='blue', label='Real Data')\n",
    "ax.scatter(anomaly_k_means_svm[0].index, anomaly_k_means_svm[0], color='red', label='Anomaly')\n",
    "plot.xlabel('Time')\n",
    "plot.legend()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure_1 only point anomalies\n",
    "\n",
    "fig, ax = plot.subplots(2, 2, figsize=(25, 12))\n",
    "ax[0][0].plot(real_data_pd[0], color='#40375c', label='Real Data')\n",
    "ax[0][0].scatter(x=anomaly_indices, y=anomaly_values, color=\"#f14235\", label=\"Anomaly\", linewidth=2)\n",
    "ax[0][0].legend(loc = \"upper right\")\n",
    "ax[0][0].set_title(\"AD by GAN-based Algorithm\", pad=15)\n",
    "\n",
    "ax[0][1].plot(real_data_pd[0], color='#40375c', label='Real Data')\n",
    "ax[0][1].scatter(anomaly_k_means[0].index, anomaly_k_means[0], color='#f14235', label='Anomaly', linewidth=2)\n",
    "ax[0][1].legend(loc = \"upper right\")\n",
    "ax[0][1].set_title(\"AD by K-Means Clustering\", pad=15)\n",
    "\n",
    "ax[1][0].plot(real_data_pd[0], color='#40375c', label='Real Data')\n",
    "ax[1][0].scatter(anomaly_isolation_forest[0].index, anomaly_isolation_forest[0], color='#f14235', label='Anomaly', linewidth=2)\n",
    "ax[1][0].legend(loc = \"upper right\")\n",
    "ax[1][0].set_title(\"AD by Isolation Forest\", pad=15)\n",
    "\n",
    "ax[1][1].plot(real_data_pd[0], color='#40375c', label='Real Data')\n",
    "ax[1][1].scatter(anomaly_svm[0].index, anomaly_svm[0], color='#f14235', label='Anomaly', linewidth=2)\n",
    "ax[1][1].legend(loc = \"upper right\")\n",
    "ax[1][1].set_title(\"AD by One-Class SVM\", pad=15)\n",
    "\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='Time')\n",
    "    \n",
    "for a in ax.flat:\n",
    "    a.label_outer()\n",
    "\n",
    "plot.rcParams.update({'font.size': 25, 'font.family': ['times-new-roman'],})\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_anomalies = 6\n",
    "\n",
    "test_accuracy_gan = (len(anomaly_indices)/num_of_anomalies) * 100\n",
    "print(\"Test Acccuracy by GAN: \" + str(round(test_accuracy_gan, 2)) + \"%\")\n",
    "\n",
    "test_accuracy_k_means = (len(anomaly_k_means[0])/num_of_anomalies) * 100\n",
    "print(\"Test Acccuracy by K_means: \" + str(round(test_accuracy_k_means, 2)) + \"%\")\n",
    "\n",
    "test_accuracy_if = (len(anomaly_isolation_forest[0])/num_of_anomalies) * 100\n",
    "print(\"Test Acccuracy by Isolation Forest: \" + str(round(test_accuracy_if, 2)) + \"%\")\n",
    "\n",
    "test_accuracy_svm = (len(anomaly_svm[0])/num_of_anomalies) * 100\n",
    "print(\"Test Acccuracy by SVM: \" + str(round(test_accuracy_svm, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 5 Point and Sequential anomlaies for demonstraion\n",
    "fig, ax = plot.subplots(1, 1, figsize=(25, 12))\n",
    "ax.plot(real_data_pd[0], color='#40375c', label='Real Data')\n",
    "ax.scatter(anomaly_indices[:1], anomaly_values[:1], color=\"#f14235\", label=\"Point Anomaly\", linewidth=3)\n",
    "ax.plot(anomaly_indices[1:], anomaly_values[1:], color=\"#f5a623\", label=\"Sequential Anomalies\", linewidth=3)\n",
    "ax.legend(loc = \"upper right\")\n",
    "# ax.set_title(\"Point and Sequential Anomalies\", pad=15)\n",
    "\n",
    "plot.rcParams.update({'font.size': 25, 'font.family': ['times-new-roman'],})\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 5 Point and Sequential anomlaies for demonstraion\n",
    "fig, ax = plot.subplots(1, 1, figsize=(25, 12))\n",
    "ax.plot(real_data_pd[0], color='#40375c', label='Time Series Data')\n",
    "ax.legend(loc = \"upper left\")\n",
    "ax.set_title(\"Time Series Example\", pad=15)\n",
    "plot.rcParams.update({'font.size': 25, 'font.family': ['times-new-roman'],})\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
